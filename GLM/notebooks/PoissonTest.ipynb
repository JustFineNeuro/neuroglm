{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test book",
   "id": "a23d9084d27256bf"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T01:41:26.097229Z",
     "start_time": "2025-01-30T01:41:26.089806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.io import loadmat\n",
    "import mat73\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from GLM import glm,utils\n",
    "import dill as pickle\n",
    "from ChangeOfMind.functions import processing as proc\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "datum = '/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/AllData/workspace.pkl'\n",
    "ff = open(datum, 'rb')\n",
    "dat = pickle.load(ff)\n",
    "formfit = pd.DataFrame(columns=('formula','subject','neuron','area','smooth_lambda'))\n",
    "from tune_sklearn import TuneGridSearchCV  # Import the TuneGridSearchCV class\n",
    "\n",
    "\n",
    "for subj in dat['psth_sess_emu'].keys():\n",
    "    sess=1\n",
    "    psth = dat['psth_sess_emu'][subj]\n",
    "    Xd = dat['Xd_sess_emu'][subj]\n",
    "    wt = dat['outputs_sess_emu'][subj]\n",
    "    \n",
    "    #Flatten neuron array\n",
    "    X_train = pd.DataFrame(columns=['relvalue','reldist','relspeed','reltime','wt','speed'])\n",
    "    psth_flat = np.concatenate(psth[sess])\n",
    "    N_neurons = psth_flat.shape[1]\n",
    "    \n",
    "    # Make design matrices and compute normalizations:\n",
    "    #Flatten first\n",
    "    Xd_flat = np.concatenate(Xd[sess])\n",
    "    Xd_flat = pd.DataFrame(Xd_flat, columns=Xd[1][0].columns)\n",
    "    \n",
    "    #Center and normalize predictors appropriately here\n",
    "    # 1. Compute relative value (get and normalize)\n",
    "    #Should be in relvalue\n",
    "    Xd_flat['relvalue']=Xd_flat['relvalue'].astype(np.float32)\n",
    "    Xd_flat['relvalue']=Xd_flat['relvalue']/Xd_flat['relvalue'].max()\n",
    "    X_train['relvalue']=Xd_flat['relvalue']-0.5\n",
    "    #Could bin\n",
    "    # X_train['relvalue'] = (X_train['relvalue'] - 3)\n",
    "    \n",
    "    #2. rel distance\n",
    "    Xd_flat['reldist']=Xd_flat['reldist'].round(2)\n",
    "    X_train['reldist']=Xd_flat['reldist']-np.mean(Xd_flat['reldist'])\n",
    "    #3. rel speed (correct normalization)\n",
    "    # relspeed: subject-cursor/max(cursor_all_trials)\n",
    "    Xd_flat['val1_disc']=(pd.cut(Xd_flat['val1'], bins=5, labels=False) + 1)\n",
    "    Xd_flat['val2_disc']=(pd.cut(Xd_flat['val2'], bins=5, labels=False) + 1)\n",
    "    \n",
    "    numer=((Xd_flat['deltaspeed1'] / Xd_flat['val1_disc']) - Xd_flat['deltaspeed2'] / Xd_flat['val2_disc'])\n",
    "    \n",
    "    Xd_flat['relspeed']=(numer-numer.min())/(numer.max()-numer.min())\n",
    "    X_train['relspeed']=Xd_flat['relspeed']-np.mean(Xd_flat['relspeed'])\n",
    "    \n",
    "    #4. rel time\n",
    "    X_train['reltime'] = Xd_flat['reltimecol']-np.mean(Xd_flat['reltimecol'])\n",
    "    \n",
    "    #5  self-speed\n",
    "    X_train['speed'] = Xd_flat['selfspeedmag']-np.mean(Xd_flat['selfspeedmag'])\n",
    "    \n",
    "    #6 wt\n",
    "    X_train['wt'] = np.concatenate(wt[sess]['wt_per_trial'])-0.5\n",
    "    \n",
    "    \n",
    "    #Make formulas\n",
    "    df_value=9\n",
    "    te_df_value=7\n",
    "    formulas=[]\n",
    "    formulas.append('y~1')\n",
    "    formulas.append(f\"y ~ cr(speed,df={df_value})\")\n",
    "    formulas.append(f\"y ~ cr(reldist,df={df_value})\")\n",
    "    formulas.append(f\"y ~ cr(wt,df={df_value})\")\n",
    "    formulas.append(f'y ~ cr(reldist,df={df_value})+cr(wt,df={df_value})')\n",
    "    formulas.append(f'y ~ cr(reldist,df={df_value})+cr(speed,df={df_value})')\n",
    "    formulas.append(f'y ~ cr(reldist,df={df_value})+cr(wt,df={df_value})+cr(speed,df={df_value})')\n",
    "    formulas.append(f\"y ~ cr(wt,df={df_value})+cr(speed,df={df_value})+te(cr(wt,df={te_df_value})+cr(speed,df={te_df_value}))\")\n",
    "    formulas.append(f\"y ~ cr(wt,df={df_value})+cr(reldist,df={df_value})+te(cr(wt,df={te_df_value})+cr(reldist,df={te_df_value}))\")\n",
    "    formulas.append(f'y ~ cr(reldist,df={df_value})+cr(wt,df={df_value})+cr(speed,df={df_value})+te(cr(wt,df={te_df_value})+cr(speed,df={te_df_value}))')\n",
    "    formulas.append(f'y ~ cr(speed,df={df_value})+cr(wt,df={df_value})+cr(reldist,df={df_value})+te(cr(wt,df={te_df_value})+cr(reldist,df={te_df_value}))')\n",
    "    \n",
    "    # formulas.append('y ~ relvalue')\n",
    "    \n",
    "    # Define different values for smoothness regularization\n",
    "    smooth_lambdas = [0.0001, 0.001, 0.01, 0.1,1.0]\n",
    "    \n",
    "    # Set up the parameter grid\n",
    "    param_grid = {\n",
    "        'formula': formulas,  # Different model formulas\n",
    "        'smooth_lambda': smooth_lambdas  # Different regularization strengths\n",
    "    }\n",
    "    # tuning={'wt':[],'reldist':[],'speed':[],'neuron':[]}\n",
    "    for i in range(psth_flat.shape[1]):\n",
    "        print(i/psth_flat.shape[1])\n",
    "        # tuning['neuron'].append(i)\n",
    "        Y= psth_flat[:,i]\n",
    "        \n",
    "        # Initialize the model\n",
    "        glm_model = glm.PoissonGLMEstimator()\n",
    "        \n",
    "        # Use GridSearchCV for cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=glm_model,\n",
    "            param_grid=param_grid,\n",
    "            scoring=make_scorer(glm.poisson_nll_scorer, greater_is_better=False),  # Use Poisson NLL\n",
    "            cv=5,  # 5-fold cross-validation\n",
    "            n_jobs=-1  # Use multiple CPU cores\n",
    "        )\n",
    "        \n",
    "        # Fit GridSearchCV on the dataset\n",
    "        grid_search.fit(X_train, Y)\n",
    "        \n",
    "        best_form=[grid_search.best_params_['formula']]\n",
    "        new_row={'subject':subj,'neuron':i,'area':dat['brain_region_emu'][subj][1][i]}\n",
    "        new_row.update(grid_search.best_params_)\n",
    "        formfit = pd.concat([formfit, pd.DataFrame([new_row])], ignore_index=True)\n",
    "\n",
    "saveto=('/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/CV_neuronglm.pkl')\n",
    "with open(saveto, 'wb') as f:\n",
    "    pickle.dump(formfit, f)\n",
    "\n",
    "    \n",
    "    # \n",
    "    # \n",
    "    # \n",
    "    # \n",
    "    # mod=glm.PoissonGLM(grid_search.best_params_['smooth_lambda'])\n",
    "    # mod.add_data(X_train,Y).make_preprocessor(formulas=best_form,metric='cv').fit(params={'cv': 5, 'shuffleTime': False})\n",
    "    # \n",
    "    # \n",
    "    # vars = utils.extract_variable_names_from_formula(grid_search.best_params_['formula'])\n",
    "    # speed = []\n",
    "    # wt = []\n",
    "    # reldist = []\n",
    "    # \n",
    "    # #Fit 1 and fix others\n",
    "    # rangers={'wt':{'range':[],'mu:':[]},'reldist':{'range':[],'mu:':[]},'speed':{'range':[],'mu':[]}}\n",
    "    # for key in rangers.keys():\n",
    "    #     rangers[key]['range']=np.linspace((mod.X[key]).min(),(mod.X[key]).max(),100)\n",
    "    #     rangers[key]['mu']=np.linspace((mod.X[key]).mean(),(mod.X[key]).mean(),100)\n",
    "    # \n",
    "    # for key in vars.keys():\n",
    "    #     #blank frame\n",
    "    #     pred_data = pd.DataFrame(columns=vars.keys())\n",
    "    #     other_keys = [k for k in vars.keys() if k != key]\n",
    "    #     pred_data[key]=rangers[key]['range']\n",
    "    #     for other_key in other_keys:\n",
    "    #         pred_data[other_key]=rangers[other_key]['mu']\n",
    "    #     \n",
    "    #     tuning[key].append(mod.predict(pred_data)*60)\n",
    "    # \n",
    "    # missing_keys = set(rangers.keys()) - set(vars.keys())\n",
    "    # if len(missing_keys) > 0:\n",
    "    #     for missing_key in missing_keys:\n",
    "    #         tuning[missing_key].append(np.zeros(100))\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ],
   "id": "f2fdff44bd1a400e",
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 104)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  File \u001B[0;32m<tokenize>:104\u001B[0;36m\u001B[0m\n\u001B[0;31m    )\u001B[0m\n\u001B[0m    ^\u001B[0m\n\u001B[0;31mIndentationError\u001B[0m\u001B[0;31m:\u001B[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Single prey",
   "id": "b17327e634e19b9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "datum = '/Users/user/PycharmProjects/PacManMain/ChangeOfMind/Files/workspace_preyn_1.pkl'\n",
    "ff = open(datum, 'rb')\n",
    "dat = pickle.load(ff)\n",
    "\n",
    "\n",
    "for subj in dat['psth_sess_emu'].keys():\n",
    "    sess=1\n",
    "    psth = dat['psth_sess_emu'][subj]\n",
    "    Xd = dat['Xd_sess_emu'][subj]\n",
    "    wt = dat['outputs_sess_emu'][subj]\n",
    "    \n",
    "    #Flatten neuron array\n",
    "    X_train = pd.DataFrame(columns=['relvalue','reldist','relspeed','reltime','wt','speed'])\n",
    "    psth_flat = np.concatenate(psth[sess])\n",
    "    N_neurons = psth_flat.shape[1]\n",
    "    \n",
    "    # Make design matrices and compute normalizations:\n",
    "\n",
    "    Xd_flat = np.concatenate(Xd[sess])\n",
    "    Xd_flat = pd.DataFrame(Xd_flat, columns=Xd[1][0].columns)\n",
    "\n",
    "    # Center and normalize predictors appropriately here\n",
    "    # 1. Compute relative value (get and normalize)\n",
    "    # Should be in relvalue\n",
    "    Xd_flat['val1'] = Xd_flat['val1'].astype(np.float32)\n",
    "    X_train['value'] = Xd_flat['val1'] / Xd_flat['val1'].max()\n",
    "    # 2. rel distance\n",
    "    Xd_flat['dist1'] = Xd_flat['dist1'].round(2)\n",
    "    \n",
    "    X_train['reldist'] = Xd_flat['dist1'] - np.mean(Xd_flat['dist1'])\n",
    "    #reldist angle\n",
    "    diff_vec_x = Xd_flat['prey1Xpos'] - Xd_flat['selfXpos']\n",
    "    diff_vec_y = Xd_flat['prey1Ypos'] - Xd_flat['selfYpos']\n",
    "    \n",
    "    ag1 = np.arctan2(diff_vec_y, diff_vec_x)\n",
    "    ag2 = np.arctan2(Xd_flat['selfYvel'], Xd_flat['selfXvel'])\n",
    "    relhead = np.mod(np.rad2deg(np.mod(ag1 - ag2, np.pi * 2)) + 180, 360) - 180\n",
    "    X_train['heading']=np.deg2rad(relhead)\n",
    "\n",
    "    \n",
    "    X_train['relspeed'] = Xd_flat['deltaspeed1'] - np.mean(Xd_flat['deltaspeed1'])\n",
    "    X_train['accel_angle']=np.arctan2(Xd_flat['selfYaccel'],Xd_flat['selfXaccel'])\n",
    "    X_train['accel_mag']=np.sqrt(Xd_flat['selfYaccel']**2+Xd_flat['selfXaccel']**2)\n",
    "    X_train['accel_mag']=X_train['accel_mag']-np.mean(X_train['accel_mag'])\n",
    "    \n",
    "    #Make formulas\n",
    "    df_value=9\n",
    "    te_df_value=7\n",
    "    formulas=[]\n",
    "    formulas.append('y~1')\n",
    "    formulas.append(f\"y ~ cr(relspeed,df={df_value})\")\n",
    "    formulas.append(f\"y ~ cr(reldist,df={df_value})\")\n",
    "    formulas.append(f\"y ~ cr(accel_mag,df={df_value})\")\n",
    "    formulas.append(f\"y ~ cc(accel_angle,df={df_value})\")\n",
    "    formulas.append(f\"y ~ cc(heading,df={df_value})\")\n",
    "    formulas.append(f\"y ~ value\")\n",
    "    formulas.append(f\"y ~ value*cr(relspeed,df={df_value})\")\n",
    "    formulas.append(f\"y ~ value*cr(redis,df={df_value})\")\n",
    "    formulas.append(f\"y ~ value*cr(accel_mag,df={df_value})\")\n",
    "    formulas.append(f\"y ~ value*cc(accel_angle,df={df_value})\")\n",
    "    formulas.append(f\"y ~ value*cc(heading,df={df_value})\")\n",
    "\n",
    "    # Define different values for smoothness regularization\n",
    "    smooth_lambdas = [0.0001, 0.001, 0.01, 0.1,1.0]\n",
    "    \n",
    "    # Set up the parameter grid\n",
    "    param_grid = {\n",
    "        'formula': formulas,  # Different model formulas\n",
    "        'smooth_lambda': smooth_lambdas  # Different regularization strengths\n",
    "    }\n",
    "    # tuning={'wt':[],'reldist':[],'speed':[],'neuron':[]}\n",
    "    for i in range(psth_flat.shape[1]):\n",
    "        print(i/psth_flat.shape[1])\n",
    "        # tuning['neuron'].append(i)\n",
    "        Y= psth_flat[:,i]\n",
    "        \n",
    "        # Initialize the model\n",
    "        glm_model = glm.PoissonGLMEstimator()\n",
    "        \n",
    "        # Use GridSearchCV for cross-validation\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=glm_model,\n",
    "            param_grid=param_grid,\n",
    "            scoring=make_scorer(glm.poisson_nll_scorer, greater_is_better=False),  # Use Poisson NLL\n",
    "            cv=5,  # 5-fold cross-validation\n",
    "            n_jobs=-1  # Use multiple CPU cores\n",
    "        )\n",
    "        \n",
    "        # Fit GridSearchCV on the dataset\n",
    "        grid_search.fit(X_train, Y)\n",
    "\n",
    "    \n"
   ],
   "id": "d1863bb7e40fe035"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Make predicted set",
   "id": "7a8471d821704813"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data=loadmat('/Users/user/PycharmProjects/PacManMain/GLM/exampleData/data4Justin.mat')\n",
    "data=pd.DataFrame(data['data'][0])\n",
    "data = data.applymap(lambda x: [item[0] for item in x])\n",
    "data = data.apply(pd.Series.explode).reset_index(drop=True)\n",
    "rewardVal=data.rewardVal\n",
    "\n",
    "data=loadmat('/Users/user/PycharmProjects/PacManMain/GLM/exampleData/data4Justin2.mat')\n",
    "\n",
    "data=pd.DataFrame(data['data'][0])\n",
    "psth=np.array(data['accspks'][0])\n",
    "\n",
    "column_names = [f'psth_{i}' for i in range(psth.shape[1])]\n",
    "\n",
    "data = data.applymap(lambda x: [item[0] for item in x])\n",
    "data = data.apply(pd.Series.explode).reset_index(drop=True)\n",
    "data['rewardVal']=rewardVal\n",
    "data['rewardVal']=data.rewardVal.astype('category')\n",
    "\n",
    "\n",
    "\n",
    "#Add in psth\n",
    "for i in range(psth.shape[1]):\n",
    "    data[f'psth_{i}'] = psth[:, i]\n",
    "\n",
    "data=data[data['rewardVal']!=0]\n",
    "# data['rewardVal']=data.rewardVal.astype('int')\n",
    "\n",
    "\n",
    "X=data[['self_spd','prey_spd','rewardVal']]\n",
    "X['prey_spd'] = pd.to_numeric(X['prey_spd'], errors='coerce')\n",
    "X['self_spd'] = pd.to_numeric(X['self_spd'], errors='coerce')\n",
    "X['prey_spd']=(X['prey_spd']/10)\n",
    "X['self_spd']=(X['self_spd']/10)\n",
    "\n",
    "y = data['psth_1']\n",
    "\n",
    "#Make formulas\n",
    "formulas=[]\n",
    "formulas.append('y ~ cr(self_spd,df=5)*cr(prey_spd, df=5)-1')\n",
    "\n",
    "formulas.append('y ~ cr(self_spd,df=5)+ cr(prey_spd, df=5)-1')\n",
    "formulas.append('y ~ cr(self_spd,df=5)-1')\n",
    "formulas.append('y ~ cr(prey_spd,df=5)-1')\n",
    "formulas.append('y ~1')\n",
    "\n",
    "mod=glm.PoissonGLM()\n",
    "mod.add_data(X,y).make_preprocessor(formulas=formulas,metric='cv',l2reg=0.001).fit(params={'cv': 5, 'shuffleTime': False})\n",
    "\n",
    "\n",
    "x1=np.linspace((mod.X['prey_spd']).min(),(mod.X['prey_spd']).max(),100)\n",
    "x2=np.linspace((mod.X['self_spd']).min(),(mod.X['self_spd']).max(),100)\n",
    "\n",
    "pred_data = pd.DataFrame({\n",
    "        'prey_spd':x1,\n",
    "        'self_spd':np.median((mod.X['self_spd']))})\n",
    "# Create a DataFrame to hold the predictions for each level of the categorical variable\n",
    "predictions=np.zeros((100,100))\n",
    "for i in range(100):\n",
    "    pred_data = pd.DataFrame({\n",
    "        'prey_spd':x1,\n",
    "        'self_spd':x2[i]\n",
    "    })\n",
    "\n",
    "    mod.predict(pred_data)\n",
    "    predictions[:,i]=np.array(mod.predicted_y)\n"
   ],
   "id": "1a81507469cd0d24"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
